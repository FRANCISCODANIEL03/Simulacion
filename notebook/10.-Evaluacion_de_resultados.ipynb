{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1162b4db-bee2-4f6f-af1d-7365360b9eaa",
   "metadata": {},
   "source": [
    "# Evaluacion de resultados\n",
    "\n",
    "En este Notebook se muestran para la evaluacion de los resultados de una prediccion con un algoritmo de Machine Learning\n",
    "\n",
    "## Dataset\n",
    "\n",
    "### Descripción \n",
    "NSL-KDD is a data set suggested to solve some of the inherent problems of the KDD'99 data set which are mentioned in. Although, this new version of the KDD data set still suffers from some of the problems discussed by McHugh and may not be a perfect representative of existing real networks, because of the lack of public data sets for network-based IDSs, we believe it still can be applied as an effective benchmark data set to help researchers compare different intrusion detection methods. Furthermore, the number of records in the NSL-KDD train and test sets are reasonable. This advantage makes it affordable to run the experiments on the complete set without the need to randomly select a small portion. Consequently, evaluation results of different research work will be consistent and comparable.\n",
    "\n",
    "## Ficheros de datos\n",
    "* <span style=\"color:green\">**KDDTrain+.ARFF**: The full NSL-KDD train set with binary labels in ARFF format</span>\n",
    "* KDDTrain+.TXT: The full NSL-KDD train set including attack-type labels and difficulty level in CSV format\n",
    "* KDDTrain+_20Percent.ARFF: A 20% subset of the KDDTrain+.arff file\n",
    "* KDDTrain+_20Percent.TXT: A 20% subset of the KDDTrain+.txt file\n",
    "* KDDTest+.ARFF: The full NSL-KDD test set with binary labels in ARFF format\n",
    "* KDDTest+.TXT: The full NSL-KDD test set including attack-type labels and difficulty level in CSV format\n",
    "* KDDTest-21.ARFF: A subset of the KDDTest+.arff file which does not include records with difficulty level of 21 out of 21\n",
    "* KDDTest-21.TXT: A subset of the KDDTest+.txt file which does not include records with difficulty level of 21 out of 21"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc5753e-7c7f-45fd-8105-3f68db0332a3",
   "metadata": {},
   "source": [
    "## Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04845fe7-3b97-449f-8e35-abd2d554d501",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arff\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6a4ab5-77f3-44bc-8965-2e8d5df5e732",
   "metadata": {},
   "source": [
    "## Funciones Auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6748e43b-b5e2-41ad-ba46-f9e45d54a230",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_kdd_dataset(data_path):\n",
    "    \"\"\"Lectura de DataSet NSL-KDD.\"\"\"\n",
    "    with open(data_path, 'r') as train_set:\n",
    "        dataset = arff.load(train_set)\n",
    "    attributes = [attr[0] for attr in dataset[\"attributes\"]]\n",
    "    return pd.DataFrame(dataset[\"data\"], columns = attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "458110a1-b44f-4a60-8a07-29007c8d9353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construcción de una función que relice le particionado completo\n",
    "def train_val_test_split(df, rsate = 42, shuffle = True, stratify = None):\n",
    "    strat = df[stratify] if stratify else None\n",
    "    train_set, test_set = train_test_split(\n",
    "        df, test_size = 0.4, random_state = rsate, shuffle = shuffle, stratify = strat)\n",
    "    strat = test_set[stratify] if stratify else None\n",
    "    val_set, test_set = train_test_split(\n",
    "        test_set, test_size = 0.5, random_state = rsate, shuffle = shuffle, stratify = strat)\n",
    "    return (train_set, val_set, test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36dd19b2-23da-41db-8272-095a56724630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construccion de un pipeline para los atributos numericos\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy = \"median\")),\n",
    "    ('rbst_scaler', RobustScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "933571b9-c1f8-4466-a882-a2ca5d5fe21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformador para codificar unicamente las columnas categoricas y devolver un DataFrame\n",
    "class CustomOneHotEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self._oh = OneHotEncoder(sparse_output = False)\n",
    "        self._columns = None\n",
    "    def fit(self, x, y = None):\n",
    "        x_cat = x.select_dtypes(include = ['object'])\n",
    "        self._columns = pd.get_dummies(x_cat).columns\n",
    "        self._oh.fit(x_cat)\n",
    "        return self\n",
    "    def transform(self, x, y = None):\n",
    "        x_copy = x.copy()\n",
    "        x_cat = x_copy.select_dtypes(include = ['object'])\n",
    "        x_num = x_copy.select_dtypes(exclude = ['object'])\n",
    "        x_cat_oh = self._oh.transform(x_cat)\n",
    "        x_cat_oh = pd.DataFrame(x_cat_oh, columns = self._columns, index = x_copy.index)\n",
    "        x_copy.drop(list(x_cat), axis = 1, inplace = True)\n",
    "        return x_copy.join(x_cat_oh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "127bfce8-ed12-48c7-8735-b1c3864507b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformador queprepara todo el DataSet llamado Pipelines y transformadores personalizados\n",
    "class DataFramePreparer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self._full_pipeline = None\n",
    "        self._columns = None\n",
    "    def fit(self, x, y = None):\n",
    "        num_attribs = list(x.select_dtypes(exclude = ['object']))\n",
    "        cat_attribs = list(x.select_dtypes(include = ['object']))\n",
    "        self._full_pipeline = ColumnTransformer([\n",
    "            (\"num\", num_pipeline, num_attribs),\n",
    "            (\"cat\", CustomOneHotEncoder(), cat_attribs),\n",
    "        ])\n",
    "        self._full_pipeline.fit(x)\n",
    "        self._columns = pd.get_dummies(x).columns\n",
    "        return self\n",
    "    def transform(self, x, y = None):\n",
    "        x_copy = x.copy()\n",
    "        x_prep = self._full_pipeline.transform(x_copy)\n",
    "        return pd.DataFrame(x_prep, columns = self._columns, index = x_copy.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ae2feb-8370-436b-8bae-1ddb258d83e6",
   "metadata": {},
   "source": [
    "## Lectura del DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4661648a-a7ba-4ec1-8bb0-c5a9d082d29e",
   "metadata": {},
   "outputs": [
    {
     "ename": "BadAttributeType",
     "evalue": "Bad @ATTRIBUTE type, at line 5.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadAttributeType\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mload_kdd_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/home/pako0311/Escritorio/Simulacion/datasets/datasets/NSL-KDD/KDDTest+.arff\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m df\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m10\u001b[39m)\n",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m, in \u001b[0;36mload_kdd_dataset\u001b[0;34m(data_path)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Lectura de DataSet NSL-KDD.\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(data_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m train_set:\n\u001b[0;32m----> 4\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[43marff\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m attributes \u001b[38;5;241m=\u001b[39m [attr[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m dataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattributes\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mDataFrame(dataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m], columns \u001b[38;5;241m=\u001b[39m attributes)\n",
      "File \u001b[0;32m~/anaconda3/envs/simulacion/lib/python3.9/site-packages/arff.py:1059\u001b[0m, in \u001b[0;36mload\u001b[0;34m(fp, encode_nominal, return_type)\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''Load a file-like object containing the ARFF document and convert it into\u001b[39;00m\n\u001b[1;32m   1046\u001b[0m \u001b[38;5;124;03ma Python object.\u001b[39;00m\n\u001b[1;32m   1047\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1056\u001b[0m \u001b[38;5;124;03m:return: a dictionary.\u001b[39;00m\n\u001b[1;32m   1057\u001b[0m \u001b[38;5;124;03m '''\u001b[39;00m\n\u001b[1;32m   1058\u001b[0m decoder \u001b[38;5;241m=\u001b[39m ArffDecoder()\n\u001b[0;32m-> 1059\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_nominal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_nominal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1060\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mreturn_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_type\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/simulacion/lib/python3.9/site-packages/arff.py:896\u001b[0m, in \u001b[0;36mArffDecoder.decode\u001b[0;34m(self, s, encode_nominal, return_type)\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ArffException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    895\u001b[0m     e\u001b[38;5;241m.\u001b[39mline \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_line\n\u001b[0;32m--> 896\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[0;32m~/anaconda3/envs/simulacion/lib/python3.9/site-packages/arff.py:892\u001b[0m, in \u001b[0;36mArffDecoder.decode\u001b[0;34m(self, s, encode_nominal, return_type)\u001b[0m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''Returns the Python representation of a given ARFF file.\u001b[39;00m\n\u001b[1;32m    878\u001b[0m \n\u001b[1;32m    879\u001b[0m \u001b[38;5;124;03mWhen a file object is passed as an argument, this method reads lines\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    889\u001b[0m \u001b[38;5;124;03m    progressively`_.\u001b[39;00m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    891\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 892\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_nominal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_nominal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mmatrix_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ArffException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    895\u001b[0m     e\u001b[38;5;241m.\u001b[39mline \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_line\n",
      "File \u001b[0;32m~/anaconda3/envs/simulacion/lib/python3.9/site-packages/arff.py:823\u001b[0m, in \u001b[0;36mArffDecoder._decode\u001b[0;34m(self, s, encode_nominal, matrix_type)\u001b[0m\n\u001b[1;32m    819\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m BadLayout()\n\u001b[1;32m    821\u001b[0m STATE \u001b[38;5;241m=\u001b[39m _TK_ATTRIBUTE\n\u001b[0;32m--> 823\u001b[0m attr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_decode_attribute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m attribute_names:\n\u001b[1;32m    825\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m BadAttributeName(attr[\u001b[38;5;241m0\u001b[39m], attribute_names[attr[\u001b[38;5;241m0\u001b[39m]])\n",
      "File \u001b[0;32m~/anaconda3/envs/simulacion/lib/python3.9/site-packages/arff.py:765\u001b[0m, in \u001b[0;36mArffDecoder._decode_attribute\u001b[0;34m(self, s)\u001b[0m\n\u001b[1;32m    763\u001b[0m     type_ \u001b[38;5;241m=\u001b[39m unicode(type_)\u001b[38;5;241m.\u001b[39mupper()\n\u001b[1;32m    764\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m type_ \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNUMERIC\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mREAL\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mINTEGER\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSTRING\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m--> 765\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m BadAttributeType()\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (name, type_)\n",
      "\u001b[0;31mBadAttributeType\u001b[0m: Bad @ATTRIBUTE type, at line 5."
     ]
    }
   ],
   "source": [
    "df = load_kdd_dataset('/home/pako0311/Escritorio/Simulacion/datasets/datasets/NSL-KDD/KDDTest+.arff')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b87c453-ce79-4308-ac34-b12b028258d1",
   "metadata": {},
   "source": [
    "## Division del DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eec9e62-b184-4d07-b0bb-d93e3f080b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Division del DataSet en los diferentes subconjuntos\n",
    "train_set, val_set, test_set = train_val_test_split(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8b8cf4-4e9d-4fba-b49e-d7e4a07dfa35",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Longitud del Training Set: \", len(train_set))\n",
    "print(\"Longitud de la Validacion: \", len(val_set))\n",
    "print(\"Longitud del Test Set: \", len(test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2aea6b-ee19-41a0-abc9-9db59389a24d",
   "metadata": {},
   "source": [
    "Para cada uno de los subconjunto, se separa las etiquetas pde las caracteristicas de entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1693d195-d605-4f63-804b-50240a5cbff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataSet general \n",
    "x_df = df.drop(\"class\", axis = 1)\n",
    "y_df = df[\"class\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbda736-9203-40ee-84c1-954b7ce8bdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataSet de entrenamiento \n",
    "x_train = train_set.drop(\"class\", axis = 1)\n",
    "y_train = train_set[\"class\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5bfef9-dcb0-4af6-a8c4-f1a4e373b16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataSet de validacion\n",
    "x_val = val_set.drop(\"class\", axis = 1)\n",
    "y_val = val_set[\"class\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecb044d-97f9-4892-a69c-34cb049bf287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataSet de test\n",
    "x_test = test_set.drop(\"class\", axis = 1)\n",
    "y_test = test_set[\"class\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be790f6c-5d8c-4295-8b54-a0dda0078cb9",
   "metadata": {},
   "source": [
    "## Preparacion del DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc0c8fa-a6d0-41e3-aa60-26a2df14930a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instanciamos nuestro transformador personalizado\n",
    "data_preparer = DataFramePreparer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5356485-c43e-47a1-9bf2-46d892f8f4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacer el fit con el DataSet General para que adquiera tdos los valores posibles \n",
    "data_preparer.fit(x_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a803de3-0d05-407c-ba7d-0e571739c1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformar el DataSet de entrenamiento\n",
    "x_train_prep = data_preparer.transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c198b07c-c843-4796-af78-b19b39695367",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a0b6d9-0b11-4713-98e8-23ef6b173e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_prep.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da41c2f3-55c3-4ee6-bcdf-77a98782269b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformar el DataSet de validacion \n",
    "x_val_prep = data_preparer.transform(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e95a177-35cf-45af-8d45-206c8b34d761",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee9a3dc-7968-499c-8b95-6a971572304a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val_prep.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854cb8cc-34e8-4eb1-9032-9f1d169bdd1f",
   "metadata": {},
   "source": [
    "## Entrenamiento del Algoritmo de Regresión Logistica"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ae2afc-fa1b-4d08-b789-2b9a07dd482d",
   "metadata": {},
   "source": [
    "El instanciamiento de un algoritmo de Machine Learning, utilizando Sklearn se realiza utilizaando los metodos expuestos por la API de Sklearn, tal y como se ha presentado en Notebooks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb246e38-9c2e-4722-8d21-9cc3cb7aec09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar el algoritmo basado en Regresión Logistica \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(max_iter = 5000)  \n",
    "clf.fit(x_train_prep, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f8bd35-e18f-4ccc-bc86-fc28b21d7380",
   "metadata": {},
   "source": [
    "## Predicción de nuevos ejemplos\n",
    "\n",
    "Realizar una predicción con el método generado anteriormente, tras el entrenamiento del algoritmo de Regresión Logistica.\n",
    "Se utilizará el subconjunto de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b89b86-02a4-401a-8dfa-9fae963ba26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(x_val_prep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2f37a5-73e3-414d-98a1-cf6b4a3aaaa9",
   "metadata": {},
   "source": [
    "## 1.- Matriz de Confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411e20b8-100b-47e3-b6c1-00d8305f0030",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414780f7-4dc7-486e-8ec4-a6a18e0a84cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "ConfusionMatrixDisplay.from_estimator(clf, x_val_prep, y_val, values_format = '3g')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da31e71-812b-4a37-bd99-a0255856db15",
   "metadata": {},
   "source": [
    "## 2.- Metricas derivadas de la Matriz de confusion "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09440696-e877-4e05-8269-0ed5053fb994",
   "metadata": {},
   "source": [
    "### Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b010de41-981d-4abc-8b1d-e7486833f233",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "\n",
    "print(\"Precisión: \",precision_score(y_val, y_pred, pos_label = 'anomaly'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e0e016-95f6-423f-81ca-67355a0e70f9",
   "metadata": {},
   "source": [
    "### Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89b79ae-aed7-480e-a1e1-16d552d562c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "\n",
    "print(\"Recall: \", recall_score(y_val, y_pred, pos_label = 'anomaly'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa493a75-ad7e-4840-8bb2-879093020eaf",
   "metadata": {},
   "source": [
    "### 3.- Curva ROC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672af045-d283-40c6-87be-4de80559fb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import RocCurveDisplay\n",
    "\n",
    "RocCurveDisplay.from_estimator(clf, x_val_prep, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1f0474-a791-45be-bb6e-8ebbdb185320",
   "metadata": {},
   "source": [
    "### Curva PR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c93fba-c1fb-4a37-975a-a7a9080d7736",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "\n",
    "PrecisionRecallDisplay.from_estimator(clf, x_val_prep, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e040c378-c33b-4043-bcf4-5ba2a9dd4336",
   "metadata": {},
   "source": [
    "### 4.-Evaluacion del Modelo con el DataSet de pruebas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95127fa-3346-47d6-a6a4-265e323cc321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformar el SubConjunto de Datos de validacion\n",
    "\n",
    "x_test_prep = data_preparer.transform(x_test)\n",
    "y_pred = clf.predict(x_test_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2828a2-1237-422d-b40e-8bfb8394daed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "ConfusionMatrixDisplay.from_estimator(clf, x_test_prep, y_test, values_format = '3g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def7526c-069c-4d09-8adc-738e201ac91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "print(\"F1_score: \", f1_score(y_test, y_pred, pos_label = 'anomaly'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ef22b9-ddd7-434c-9c30-4afbbfd37382",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
